{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "22531ca9-e756-46d1-b70a-3e471d5c92a8",
      "metadata": {
        "id": "22531ca9-e756-46d1-b70a-3e471d5c92a8"
      },
      "source": [
        "# Master Thesis on the Semantics of (made-up) Names\n",
        "\n",
        "* Author: Aron Joosse\n",
        "* Supervisor: Giovanni Cassani\n",
        "* Institution: Tilburg University\n",
        "\n",
        "Can take inspiration from: https://github.com/Masetto96/BA-Thesis-form-meaning-mapping/blob/master/form_meaning_mapping.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6549cc30-115e-4d41-a905-85e232d32540",
      "metadata": {
        "id": "6549cc30-115e-4d41-a905-85e232d32540"
      },
      "source": [
        "# Library Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9e01d4f6-9943-40fb-9f85-ca2aa53b4650",
      "metadata": {
        "id": "9e01d4f6-9943-40fb-9f85-ca2aa53b4650",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c77a8fb9-f976-4007-ebd8-246563373dd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.7/dist-packages (0.9.2)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext) (1.21.5)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.7/dist-packages (from fasttext) (2.9.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (3.2.3)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.8.2)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.5)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.0.13)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.6.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.62.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.10.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.7)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n",
            "Collecting en-core-web-sm==3.2.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl (13.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.9 MB 497 kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.2.0) (3.2.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.10.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.62.3)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.13)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.6.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.9.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.11.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.21.5)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (57.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (21.3)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.8.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.7)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (5.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "!pip install fasttext --progress-bar off\n",
        "!pip install -U spacy --progress-bar off\n",
        "!python -m spacy download en_core_web_sm\n",
        "import fasttext\n",
        "import spacy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92f1ffd0-4597-433a-b9c7-bb2423556386",
      "metadata": {
        "id": "92f1ffd0-4597-433a-b9c7-bb2423556386"
      },
      "source": [
        "# Data Import"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Being able to access Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True) "
      ],
      "metadata": {
        "id": "_kihXMIxsBnq",
        "outputId": "7abe9401-3049-47c9-d057-917f1bd5f459",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "_kihXMIxsBnq",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Getting the list of madeup names:\n",
        "\n",
        "ratings_csv = pd.read_csv(\"drive/MyDrive/Thesis/Data/giovanni_email_data/avgRatings_annotated.csv\",\n",
        "                          usecols = [\"name\", \"name_type\"])\n",
        "\n",
        "ratings_csv.head(10)\n",
        "\n",
        "madeup_names = []\n",
        "\n",
        "for i in ratings_csv.index:                                           ## I can do exactly the same thing for talking & real\n",
        "  if ratings_csv[\"name_type\"][i] == \"madeup\":\n",
        "    madeup_names.append(str(ratings_csv[\"name\"][i]))\n",
        "\n",
        "madeup_names_lower = list(map(lambda x: x.lower(), madeup_names))\n",
        "\n",
        "print(madeup_names[:5])\n",
        "print(len(madeup_names))\n",
        "print(madeup_names_lower[:5])\n",
        "print(len(madeup_names_lower))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AUEyOhEpf74",
        "outputId": "edbb91da-3b48-4eb0-8514-443f88289f47"
      },
      "id": "0AUEyOhEpf74",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Alastor', 'Alecto', 'Amabala', 'Araminta', 'Arcturus']\n",
            "60\n",
            "['alastor', 'alecto', 'amabala', 'araminta', 'arcturus']\n",
            "60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NdAKmpO_raz-"
      },
      "id": "NdAKmpO_raz-",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "34910b3e-c2f9-4d54-983d-e75c2127f4db",
      "metadata": {
        "id": "34910b3e-c2f9-4d54-983d-e75c2127f4db"
      },
      "source": [
        "## COCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "bf7f61e8-e967-4ab9-895e-6fb974df4fc4",
      "metadata": {
        "id": "bf7f61e8-e967-4ab9-895e-6fb974df4fc4"
      },
      "outputs": [],
      "source": [
        "path = \"drive/My Drive/Thesis/Data/CoCA/Text/\"\n",
        "unclean_path = path + \"texts_combined/all_texts_combined.txt\"\n",
        "unclean_corpus = open(unclean_path).read()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(unclean_corpus))\n",
        "print(unclean_corpus[:100])"
      ],
      "metadata": {
        "id": "cuIyN1lBMe05",
        "outputId": "bba8486f-3211-46e7-e2fa-aa3adce7d976",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "cuIyN1lBMe05",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2977527143\n",
            "@@4170367 Headnote # A puzzle has long pervaded the criminal law : why are two offenders who commit \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a35ba177-63c9-43e0-8eb0-cc41ada452d6",
      "metadata": {
        "id": "a35ba177-63c9-43e0-8eb0-cc41ada452d6"
      },
      "source": [
        "## Names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "efb0d50d-543f-4483-9b58-83812e4c7418",
      "metadata": {
        "id": "efb0d50d-543f-4483-9b58-83812e4c7418"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45b17c25-4631-4971-8c9e-9b13b9322a08",
      "metadata": {
        "id": "45b17c25-4631-4971-8c9e-9b13b9322a08"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c46490a-70a1-41ae-8f63-ccf7fb08da08",
      "metadata": {
        "id": "6c46490a-70a1-41ae-8f63-ccf7fb08da08"
      },
      "source": [
        "\n",
        "## Cleaning Corpus"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Loading the English spacy pipeline and removing stopwords\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "nlp.max_length = 10000000000\n",
        "\n",
        "nlp.Defaults.stop_words.remove('him')\n",
        "nlp.Defaults.stop_words.remove('her')\n",
        "nlp.Defaults.stop_words.remove('hers')\n",
        "nlp.Defaults.stop_words.remove('his')\n",
        "nlp.Defaults.stop_words.remove('he')\n",
        "nlp.Defaults.stop_words.remove('she')\n",
        "nlp.Defaults.stop_words.remove('himself')\n",
        "nlp.Defaults.stop_words.remove('herself')"
      ],
      "metadata": {
        "id": "xqknf8oNouf3"
      },
      "id": "xqknf8oNouf3",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_corpus_sentenced(data, corpus_dict, index):\n",
        "  # Tokenization\n",
        "  with nlp.select_pipes(disable=[\"lemmatizer\", \"tok2vec\", \"tagger\", \"parser\"]):\n",
        "    nlp.enable_pipe(\"senter\")\n",
        "    doc = nlp(data)\n",
        "\n",
        "  sentence = \"\"\n",
        "\n",
        "  for token in doc:\n",
        "    if token.is_sent_start is True:\n",
        "      if sentence == \"\":\n",
        "        continue\n",
        "      else:\n",
        "        corpus_dict[index] = sentence\n",
        "        sentence = \"\"\n",
        "        index += 1\n",
        "    \n",
        "    if token.is_upper is True:\n",
        "      continue\n",
        "    elif token.is_stop is True:\n",
        "      continue\n",
        "    elif str(token).lower() in madeup_names_lower:\n",
        "      continue\n",
        "    elif token.is_alpha:\n",
        "      sentence += str(token).lower()\n",
        "\n",
        "  return corpus_dict, index"
      ],
      "metadata": {
        "id": "_GxXQaOBOa9N"
      },
      "id": "_GxXQaOBOa9N",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_dict = {}\n",
        "index = 0\n",
        "\n",
        "prev_i = 0\n",
        "\n",
        "for i in range(2, 2976, 2):\n",
        "  print(i)\n",
        "  i *= 1000000\n",
        "  corpus_dict, index = clean_corpus_sentenced(unclean_corpus[prev_i:i],\n",
        "                                              corpus_dict,\n",
        "                                              index)\n",
        "  prev_i = i\n",
        "\n",
        "corpus_dict, index = clean_corpus_sentenced(unclean_corpus[prev_i:],\n",
        "                                            corpus_dict,\n",
        "                                            index)\n",
        "\n",
        "print(\"----------------------\")\n",
        "print(len(corpus_dict), index)"
      ],
      "metadata": {
        "id": "yrkJY7cyAQdB",
        "outputId": "65c52091-4850-4941-bdab-6835c4850f39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "yrkJY7cyAQdB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "4\n",
            "6\n",
            "8\n",
            "10\n",
            "12\n",
            "14\n",
            "16\n",
            "18\n",
            "20\n",
            "22\n",
            "24\n",
            "26\n",
            "28\n",
            "30\n",
            "32\n",
            "34\n",
            "36\n",
            "38\n",
            "40\n",
            "42\n",
            "44\n",
            "46\n",
            "48\n",
            "50\n",
            "52\n",
            "54\n",
            "56\n",
            "58\n",
            "60\n",
            "62\n",
            "64\n",
            "66\n",
            "68\n",
            "70\n",
            "72\n",
            "74\n",
            "76\n",
            "78\n",
            "80\n",
            "82\n",
            "84\n",
            "86\n",
            "88\n",
            "90\n",
            "92\n",
            "94\n",
            "96\n",
            "98\n",
            "100\n",
            "102\n",
            "104\n",
            "106\n",
            "108\n",
            "110\n",
            "112\n",
            "114\n",
            "116\n",
            "118\n",
            "120\n",
            "122\n",
            "124\n",
            "126\n",
            "128\n",
            "130\n",
            "132\n",
            "134\n",
            "136\n",
            "138\n",
            "140\n",
            "142\n",
            "144\n",
            "146\n",
            "148\n",
            "150\n",
            "152\n",
            "154\n",
            "156\n",
            "158\n",
            "160\n",
            "162\n",
            "164\n",
            "166\n",
            "168\n",
            "170\n",
            "172\n",
            "174\n",
            "176\n",
            "178\n",
            "180\n",
            "182\n",
            "184\n",
            "186\n",
            "188\n",
            "190\n",
            "192\n",
            "194\n",
            "196\n",
            "198\n",
            "200\n",
            "202\n",
            "204\n",
            "206\n",
            "208\n",
            "210\n",
            "212\n",
            "214\n",
            "216\n",
            "218\n",
            "220\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pickle_out = open(path + \"corpus_dict.pickle\", \"wb\")\n",
        "pickle.dump(corpus_dict, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "drive.flush_and_unmount()\n",
        "print('All changes made in this colab session should now be visible in Drive.')"
      ],
      "metadata": {
        "id": "wVPMKCOeBMOo"
      },
      "id": "wVPMKCOeBMOo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a34cc32e-33c0-4f47-a08f-e7b37dd30f8a",
      "metadata": {
        "id": "a34cc32e-33c0-4f47-a08f-e7b37dd30f8a"
      },
      "outputs": [],
      "source": [
        "def clean_corpus_unsentenced(data):\n",
        "    # Tokenization\n",
        "    with nlp.select_pipes(disable=[\"lemmatizer\", \"tok2vec\", \"tagger\", \"parser\"]):\n",
        "      nlp.enable_pipe(\"senter\")\n",
        "      doc = nlp(data)\n",
        "    print(doc[:150])\n",
        "\n",
        "    doc_filtered = []\n",
        "\n",
        "    for token in doc:\n",
        "      if token.is_upper is True:\n",
        "        continue\n",
        "      elif token.is_stop is True:\n",
        "        continue\n",
        "      elif str(token).lower() in madeup_names_lower:\n",
        "        continue\n",
        "      elif token.is_alpha:\n",
        "        doc_filtered.append(str(token).lower())\n",
        "      else: \n",
        "        continue\n",
        "\n",
        "    doc_filtered = \" \".join(doc_filtered)\n",
        "\n",
        "    print(doc_filtered[:500])\n",
        "\n",
        "    # Remove words with freq < XX\n",
        "\n",
        "clean_corpus_unsentenced(unclean_corpus)#[:1000000])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a09e790a-e08f-4144-b01e-25af29a8816f",
      "metadata": {
        "id": "a09e790a-e08f-4144-b01e-25af29a8816f"
      },
      "source": [
        "## Training fastText and Validating on Word Embeddings Benchmark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d3909f0-5298-4ef8-b578-c759a62ab17c",
      "metadata": {
        "id": "0d3909f0-5298-4ef8-b578-c759a62ab17c"
      },
      "outputs": [],
      "source": [
        "# Skipgram model :\n",
        "#model = fasttext.train_unsupervised('data.txt', model='skipgram')\n",
        "\n",
        "#model.save_model(\"model_filename.bin\")\n",
        "\n",
        "#model = fasttext.load_model(\"model_filename.bin\")\n",
        "\n",
        "#model.get_nearest_neighbors('asparagus')\n",
        "\n",
        "#In a similar spirit, one can play around with word analogies. For example, we can see if our model can guess what is to France, and what Berlin is to Germany.\n",
        "#This can be done with the analogies functionality. It takes a word triplet (like Germany Berlin France) and outputs the analogy:\n",
        "#model.get_analogies(\"berlin\", \"germany\", \"france\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.flush_and_unmount()\n",
        "print('All changes made in this colab session should now be visible in Drive.')"
      ],
      "metadata": {
        "id": "MCJ592ZYMSXB",
        "outputId": "7ef56a52-2e44-478d-de55-13a6292ad0cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "MCJ592ZYMSXB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All changes made in this colab session should now be visible in Drive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aaa3cc3c-e1a4-489b-b0c6-e25bd045783f",
      "metadata": {
        "id": "aaa3cc3c-e1a4-489b-b0c6-e25bd045783f"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "MA Thesis Semantics of Names.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}