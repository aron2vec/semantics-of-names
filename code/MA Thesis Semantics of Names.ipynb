{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "22531ca9-e756-46d1-b70a-3e471d5c92a8",
      "metadata": {
        "id": "22531ca9-e756-46d1-b70a-3e471d5c92a8"
      },
      "source": [
        "# Master Thesis on the Semantics of (made-up) Names\n",
        "\n",
        "* Author: Aron Joosse\n",
        "* Supervisor: Giovanni Cassani\n",
        "* Institution: Tilburg University\n",
        "\n",
        "Can take inspiration from: https://github.com/Masetto96/BA-Thesis-form-meaning-mapping/blob/master/form_meaning_mapping.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6549cc30-115e-4d41-a905-85e232d32540",
      "metadata": {
        "id": "6549cc30-115e-4d41-a905-85e232d32540"
      },
      "source": [
        "# Library Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9e01d4f6-9943-40fb-9f85-ca2aa53b4650",
      "metadata": {
        "id": "9e01d4f6-9943-40fb-9f85-ca2aa53b4650",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc5d081d-e4a0-470e-92e9-3577ceadc11e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[?25l\n",
            "\u001b[?25hCollecting pybind11>=2.2\n",
            "  Using cached pybind11-2.9.1-py2.py3-none-any.whl (211 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext) (1.21.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3130761 sha256=6d5161767b45fdf2a2878656227e8940ff4568c6275bf72861385dc786ac5f7e\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/ca/bf/b020d2be95f7641801a6597a29c8f4f19e38f9c02a345bab9b\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.9.1\n"
          ]
        }
      ],
      "source": [
        "!pip install fasttext --progress-bar off\n",
        "import fasttext\n",
        "import spacy\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92f1ffd0-4597-433a-b9c7-bb2423556386",
      "metadata": {
        "id": "92f1ffd0-4597-433a-b9c7-bb2423556386"
      },
      "source": [
        "# Data Import"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Being able to access Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True) "
      ],
      "metadata": {
        "id": "_kihXMIxsBnq",
        "outputId": "6c6abbe0-8185-41a2-c10b-e26259931495",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "_kihXMIxsBnq",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.flush_and_unmount()\n",
        "print('All changes made in this colab session should now be visible in Drive.')"
      ],
      "metadata": {
        "id": "WEQ16w_WsydU",
        "outputId": "a7723af4-7932-457d-dbf7-83ba3f4cd119",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "WEQ16w_WsydU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All changes made in this colab session should now be visible in Drive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Getting the list of madeup names:\n",
        "\n",
        "ratings_csv = pd.read_csv(\"drive/MyDrive/Thesis/Data/giovanni_email_data/avgRatings_annotated.csv\",\n",
        "                          usecols = [\"name\", \"name_type\"])\n",
        "\n",
        "ratings_csv.head(10)\n",
        "\n",
        "madeup_names = []\n",
        "\n",
        "for i in ratings_csv.index:\n",
        "  if ratings_csv[\"name_type\"][i] == \"madeup\":\n",
        "    madeup_names.append(str(ratings_csv[\"name\"][i]))\n",
        "\n",
        "madeup_names_lower = list(map(lambda x: x.lower(), madeup_names))\n",
        "\n",
        "print(madeup_names)\n",
        "print(len(madeup_names))\n",
        "print(madeup_names_lower)\n",
        "print(len(madeup_names_lower))"
      ],
      "metadata": {
        "id": "0AUEyOhEpf74",
        "outputId": "fcdb74fb-ae33-4444-d64f-4c6fc4b8c4f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "0AUEyOhEpf74",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Alastor', 'Alecto', 'Amabala', 'Araminta', 'Arcturus', 'Argus', 'Arobynn', 'Asim', 'Brum', 'Cardan', 'Chaol', 'Chi', 'Cooki', 'Dalip', 'Dumpa', 'Elide', 'Farder', 'Fenrir', 'Fortuna', 'Gmork', 'Goha', 'Griphook', 'Grunter', 'Hannerl', 'Hepzibah', 'Inej', 'Ione', 'Iorek', 'Jungli', 'Kaisa', 'Kaz', 'Kreacher', 'Lak', 'Levana', 'Lorcan', 'Luft', 'Minna', 'Miskouri', 'Mogget', 'Morgra', 'Muffet', 'Mundungus', 'Neoma', 'Nergui', 'Nitasha', 'Penthe', 'Robbo', 'Saiorse', 'Schaffa', 'Serafina', 'Skellig', 'Spink', 'Steg', 'Talentino', 'Tasha', 'Tenar', 'Titania', 'Yozadah', 'Zahara', 'Zubaida']\n",
            "60\n",
            "['alastor', 'alecto', 'amabala', 'araminta', 'arcturus', 'argus', 'arobynn', 'asim', 'brum', 'cardan', 'chaol', 'chi', 'cooki', 'dalip', 'dumpa', 'elide', 'farder', 'fenrir', 'fortuna', 'gmork', 'goha', 'griphook', 'grunter', 'hannerl', 'hepzibah', 'inej', 'ione', 'iorek', 'jungli', 'kaisa', 'kaz', 'kreacher', 'lak', 'levana', 'lorcan', 'luft', 'minna', 'miskouri', 'mogget', 'morgra', 'muffet', 'mundungus', 'neoma', 'nergui', 'nitasha', 'penthe', 'robbo', 'saiorse', 'schaffa', 'serafina', 'skellig', 'spink', 'steg', 'talentino', 'tasha', 'tenar', 'titania', 'yozadah', 'zahara', 'zubaida']\n",
            "60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NdAKmpO_raz-"
      },
      "id": "NdAKmpO_raz-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "34910b3e-c2f9-4d54-983d-e75c2127f4db",
      "metadata": {
        "id": "34910b3e-c2f9-4d54-983d-e75c2127f4db"
      },
      "source": [
        "## COCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "bf7f61e8-e967-4ab9-895e-6fb974df4fc4",
      "metadata": {
        "id": "bf7f61e8-e967-4ab9-895e-6fb974df4fc4"
      },
      "outputs": [],
      "source": [
        "path = \"drive/My Drive/Thesis/Data/CoCA/Text/\"\n",
        "unclean_path = path + \"texts_combined/all_texts_combined.txt\"\n",
        "unclean_corpus = open(unclean_path).read()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UQGLD_X0Qk-g"
      },
      "id": "UQGLD_X0Qk-g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(unclean_corpus))\n",
        "print(unclean_corpus[:100])"
      ],
      "metadata": {
        "id": "cuIyN1lBMe05",
        "outputId": "281a9f74-4f9e-4094-a778-a5455e1432d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "cuIyN1lBMe05",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2977527143\n",
            "@@4170367 Headnote # A puzzle has long pervaded the criminal law : why are two offenders who commit \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a35ba177-63c9-43e0-8eb0-cc41ada452d6",
      "metadata": {
        "id": "a35ba177-63c9-43e0-8eb0-cc41ada452d6"
      },
      "source": [
        "## Names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efb0d50d-543f-4483-9b58-83812e4c7418",
      "metadata": {
        "id": "efb0d50d-543f-4483-9b58-83812e4c7418"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45b17c25-4631-4971-8c9e-9b13b9322a08",
      "metadata": {
        "id": "45b17c25-4631-4971-8c9e-9b13b9322a08"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c46490a-70a1-41ae-8f63-ccf7fb08da08",
      "metadata": {
        "id": "6c46490a-70a1-41ae-8f63-ccf7fb08da08"
      },
      "source": [
        "\n",
        "## Cleaning Corpus"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Loading the English spacy pipeline and removing stopwords\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "nlp.max_length = 10000000000\n",
        "\n",
        "nlp.Defaults.stop_words.remove('him')\n",
        "nlp.Defaults.stop_words.remove('her')\n",
        "nlp.Defaults.stop_words.remove('hers')\n",
        "nlp.Defaults.stop_words.remove('his')\n",
        "nlp.Defaults.stop_words.remove('he')\n",
        "nlp.Defaults.stop_words.remove('she')\n",
        "nlp.Defaults.stop_words.remove('himself')\n",
        "nlp.Defaults.stop_words.remove('herself')"
      ],
      "metadata": {
        "id": "xqknf8oNouf3"
      },
      "id": "xqknf8oNouf3",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "a34cc32e-33c0-4f47-a08f-e7b37dd30f8a",
      "metadata": {
        "id": "a34cc32e-33c0-4f47-a08f-e7b37dd30f8a",
        "outputId": "7e75934b-8129-4ab5-e07c-c76fc8f070f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@@4170367 Headnote # A puzzle has long pervaded the criminal law : why are two offenders who commit the same criminal act punished differently when one of them , due to circumstances beyond her control , causes more harm than the other ? This tradition of result-based differential\n",
            "headnote puzzle long pervaded criminal law offenders commit criminal act punished differently circumstances her control causes harm tradition result based differential punishment practice varying offe\n"
          ]
        }
      ],
      "source": [
        "def clean_corpus_unsentenced(data):\n",
        "    # Tokenization\n",
        "    doc = nlp(data)\n",
        "    print(doc[:50])\n",
        "\n",
        "    doc_filtered = []\n",
        "\n",
        "    madeup_names = []\n",
        "\n",
        "    for token in doc:\n",
        "      if token.is_upper is True:\n",
        "        continue\n",
        "      elif token.is_stop is True:\n",
        "        continue\n",
        "      elif str(token).lower() in madeup_names_lower:\n",
        "        continue\n",
        "      elif token.is_alpha:\n",
        "        doc_filtered.append(str(token).lower())\n",
        "\n",
        "    doc_filtered = \" \".join(doc_filtered)\n",
        "\n",
        "    print(doc_filtered[:200])\n",
        "\n",
        "    # Remove all words that are full-caps\n",
        "    IS_UPPER = True\n",
        "\n",
        "    # Lowercase\n",
        "    \n",
        "\n",
        "    # Remove non-letters (punctuation and numbers)\n",
        "    IS_PUNCT = True \n",
        "    LIKE_NUM = True \n",
        "    \n",
        "    # Removing stopwords: DO NOT REMOVE PRONOUNS, HIM HER ETC.\n",
        "    IS_STOP = True\n",
        "\n",
        "\n",
        "    # Remove made-up names from dataset\n",
        "\n",
        "    # Remove words with freq < XX\n",
        "\n",
        "clean_corpus_unsentenced(unclean_corpus[:1000000])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_corpus_sentenced(data):\n",
        "    # Tokenization\n",
        "    doc = nlp(data)\n",
        "    print(doc[:50])\n",
        "\n",
        "    # Split into sentences\n",
        "    sents = list(doc.sents)\n",
        "    print(sents[:3])\n",
        "\n",
        "    # Remove all words that are full-caps\n",
        "    IS_UPPER = True\n",
        "\n",
        "    # Lowercase\n",
        "    \n",
        "\n",
        "    # Remove non-letters (punctuation and numbers)\n",
        "    IS_PUNCT = True \n",
        "    LIKE_NUM = True \n",
        "    \n",
        "    # Removing stopwords: DO NOT REMOVE PRONOUNS, HIM HER ETC.\n",
        "    IS_STOP = True\n",
        "    #stop_words = set(stopwords.words('english'))\n",
        "    #stop_words.remove('him')\n",
        "    #stop_words.remove('her')\n",
        "    #stop_words.remove('hers')\n",
        "    #stop_words.remove('his')\n",
        "    #stop_words.remove('he')\n",
        "    #stop_words.remove('she')\n",
        "    #no_stop = []\n",
        "    #for sent in lemma_sent:\n",
        "    #    tokens_without_sw = [word for word in sent if not word in stop_words]\n",
        "    #    no_stop.append(tokens_without_sw)\n",
        "\n",
        "    # Remove made-up names from dataset\n",
        "\n",
        "    # Remove words with freq < XX\n",
        "\n",
        "clean_corpus_sentenced(unclean_corpus[:10000])"
      ],
      "metadata": {
        "id": "_GxXQaOBOa9N",
        "outputId": "c7326319-72b3-4460-8efe-4535188b61ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "_GxXQaOBOa9N",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3000000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.flush_and_unmount()\n",
        "print('All changes made in this colab session should now be visible in Drive.')"
      ],
      "metadata": {
        "id": "MCJ592ZYMSXB",
        "outputId": "7ef56a52-2e44-478d-de55-13a6292ad0cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "MCJ592ZYMSXB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All changes made in this colab session should now be visible in Drive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a09e790a-e08f-4144-b01e-25af29a8816f",
      "metadata": {
        "id": "a09e790a-e08f-4144-b01e-25af29a8816f"
      },
      "source": [
        "## Training fastText and Validating on Word Embeddings Benchmark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d3909f0-5298-4ef8-b578-c759a62ab17c",
      "metadata": {
        "id": "0d3909f0-5298-4ef8-b578-c759a62ab17c"
      },
      "outputs": [],
      "source": [
        "# Skipgram model :\n",
        "#model = fasttext.train_unsupervised('data.txt', model='skipgram')\n",
        "\n",
        "#model.save_model(\"model_filename.bin\")\n",
        "\n",
        "#model = fasttext.load_model(\"model_filename.bin\")\n",
        "\n",
        "#model.get_nearest_neighbors('asparagus')\n",
        "\n",
        "#In a similar spirit, one can play around with word analogies. For example, we can see if our model can guess what is to France, and what Berlin is to Germany.\n",
        "#This can be done with the analogies functionality. It takes a word triplet (like Germany Berlin France) and outputs the analogy:\n",
        "#model.get_analogies(\"berlin\", \"germany\", \"france\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aaa3cc3c-e1a4-489b-b0c6-e25bd045783f",
      "metadata": {
        "id": "aaa3cc3c-e1a4-489b-b0c6-e25bd045783f"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "MA Thesis Semantics of Names.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}